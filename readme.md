# Azure Design Technologies for Cloud Configuration

I have created this repository for my self learning and reference for expert Cloud Architect certifications

## Deployment cycle for application

- **Create a VM and a virtual network**
    - Specify inbound ports - The RDP is usually automatically selected, you can also add port 80
    - You will get an OS level disk as well as a temporary D drive, you can also add an additional disk for database
    - Select default encryption at rest
    - The VM can have a public IP address if it is hosting a web application that will be accessed by the public
        - A public IP address can also be added at a later time
    - Create a **virtual network** as you creat a VM 
        - Primary virtual network interface - has its own IP address, used for internal communication
    - An NSG is also created the controls permissions for the ports

- **Create a Storage account**
    - Azure blob service - The storage capacity automatically grows
    - While you can store data on your local VM - the storage account offers the flexibility of increasing capacity over time, limited options with the VM
    - Isolation of compute and the storage environment - data or the application are not dependent on eachother - especialy if the VM crashes, you can always create a new VM and connect it to the same storage account
    - Specifications
        - Account name, Geo-redundant storage, locally redundant storage is the least expensive
    - Go to the `Storage account resource || Under data storage: Containers (blob service), fileshares (across VMs), Queues (messaging), tables (No SQL like data)`

- **Creating an Azure SQL database** Platform as a service (PaaS)
    - Note that the SQL server, Database and the storage account must be in the same region
    - When you use AZURE SQL, you do not have to manually manage the underlying VM hosting the database, which means that you do not have to install the Azure SQL service engine, no security or patching of the database
    - You can create the SQL database from the main resources as usual
        - Specifications
            - `Create a server `- This is for logging into the SQL database server. It has 2 components, the server that hosts the database and the databse itself
                - Server name- must be unique
                - Admin login details
                - Select pricing models for database - `basic,standard, premium` - These are based on DTUs, data transfer units - costs are estimated per month
                - Select backup storage redundancy
                - Specify the connectivity options - a firewall is connected by default - options: No access, public endpoint, private endpoint
                - You can add your current computer IP address to the firewall rules as well as permit Azure service/resources to access the server
                - You can use **SQL server management studio** as you work with SQL databases - install this tool on your local machine to access the server 
    - Once created , you can locate the database in resources by its name, you can run the SQL server management studio
        - The server name is the webaddress of the SQL server which you can locate from the database resource homepage that you created and you use the login credentials in order to connect

    - **Building an appliation**
        - Will be hosted on an Azure VM and Azure webapp
        - The first part is setting up MYSQL server and a storage account and creating the required tables in the MYSQL database
            - **Setting up tables in the SQL database**
                - Use SQL server management studio to create tables and insert values
                - Select the database by name right click - new query and then you can paste your commands > click execute
                - Note that in the database, only the image links are stored, but you can store the images in the Azure storage account
            - **Uploading the images into the storage account**
                - Go to the `storage account || containers > create a new container and call it images > select Blob under public access level`
                - Open images and upload the file. You will get the image url
        - **Writing the code for application**
            - You can use various backend languages like .net, node, java. This program will have a frontend and a backend
            - The backend portion will contain the queries for database
        - **Setting up a webserver on VM to publish application**
            - Go to the `server dashboard > roles and features> select role based> check Webserver IIS > next and then check management services under management tools to allow solutions from virtual studio`
            - Open internet information services manager
                - Select management service and then click enable remote connections. Then click apply and start - this ensures that the webserver will take requests from virtual studio
                - Turn off enhanced security configuration from the main dashboard
            - Then you can download and install the .Net core 3.1 to configure the server to run a .net application - you have to select the `windows hosting bundle` - There is a different installation file based on the type of OS - for example there is a different one for linux
            - Next you have to install another software `web deploy` which deploys the application on to the internet information services
                - **Configure a DNS name**
                    - Go to the VM resource > click not configured under DNS name > type a DNS name label
                    - Go to the VM resource || networking > Add inbound rule to allow port 8172, the port that you assigned with the management service when configuring IIS on the VM
        - Once the installations are complete. You then have to create a `webapp resource` in Azure
            - **Create webapp from main resources > Create a resorce**
                - Give it a name
                - Select code vs container for now and select runtime stack as .Net core 3.1(LTS)
                - Select a region, and it will automatically select a new `app service plan`, you can also `select the sku such as the basic app service plan`
                - For the monitoring of your app you can create a new resource called `application insights` - give name and specify the region
                - Once the deployment is complete, go to the resource, you will find the url of the webapp. If you paste it in the browser, it will show a default webpage
                - Once all these steps are complete, the app will be deployed on the Vm as a webapp

        - **Application Monitoring**
            - Finally after the app has been configured and deployed. You can then setup monitoring, which will assess logs and you can configure alerts etc
            - You can select between static and dynamic routes
            - You can also create action groups, dictating what to do when a threshold is met. You can configure to e-mail and administrator or you can run scripts in response to an alert
        - **Configure logs** 
            - **Create Log analytics workspace** and connect the VM to it
            - Install an analytics agent on the VM this is what 'connect' does
            - You can then configure the agent to specify what type of logs are you looking to transfer to the workspace like events performance etc
            - Logs can be grouped into various categories

        - **NSG flow logs**
            - Captures logs for traffic - IP flows - useful for the security team
            - Useful information like source and destination IP and ports and the outcome of the address
            - You can locate the NSG group by goting to the `VM resource || networking`
            - When you click on the network security group, you will see there is an option for `flow logs` - turn it on, select the version- version 2 has additional information about the packaging of bit size etc
            - Logs are stored in the storage account - so a storage account must be linked with flow log settings. Once the account has been linked, you can verify it by going to the storage account and you will notice a new flow logs container
                - **Network watcher**
                    - This is another service that analyzes the traffic
                    - Search for network watcher from general resources `Network watcher || NSG flow logs > turn on traffic analytics status`
                    - Then also select the log analytics workspace
                    - You can specify the processing interval to create visualizations
                    - To view these visualizations go to `Network watcher || traffic analytics`
                    - There are options for malacious traffic and blocked traffic for a more granular analysis
                    - **Service Map**
                        - This feature offers a more in depth assessment of what processess are running on the VMs - Also provides the external ips and port numbers the VMs are connected to - in the form of a 'service map'
                        - Go to `workspace resource || Service map` to issue an agent. This can be done with a command that will install an Azure monitoring dependency agent as an extension
                        - Note that when you are first running the powershell, you may have to select a storage account for filesharing before you can run the commands
                        - Below is the command to install this agent
                        - `Set-AzVMExtension -ExtensionName "Microsoft.Azure.Monitoring.DependencyAgent" -ResourceGroupName "new-grp" -VMName "demovm" -Publisher "Microsoft.Azure.Monitoring.DependencyAgent" -ExtensionType "DependencyAgentWindows" -TypeHandlerVersion 9.5 -Location NorthEurope`
                        - The service map now created, needs to be added to the workspace
                            - `workspace resource || workspace summary under general > add > in th search type service map > Create service map solution`
                            - Once created, under the `workspace resource || summary` you will be able to see the service map
            
            - **Azure SQL diagnostics**
                - GO to the `SQL DB resource || disgnostics under monitoring > Add diagnostic setting`
                - Then you can stream various types of logs like errors, timeouts, basic metrics, by selecting their category and then also selecting the destination details by checking 'send to log analytics workspace' Then you can select the log analytics workspace reseource
                - This setting will forward all the SQL diagnostics data to log analytics workspace

- You can review all the sign ins to the Azure AD by selecting the Azure Active directory from the main left panel and then you can select Users
- You can click the `default directory` from top left and then select `sign-ins` under monitoring - It will show all the sign in activity
- You can add a diagnostic setting - where you can select various type of logs such as `audit logs, signin logs` etc to a certain destination including analytics workspace or storage account or an event hub
    - Once this setting has been enabled. You can verify it by going to `work space resource || log management`

## Costing Estimates
 - Pricing calculator - you can get to it by searching for `Azure pricing calculator` 
    - There are various categories for which you can estimate costs like VM, storage accounts, SQL etc
    - **VM**
        - Windows VM cost more than linux due to licensing, almost double the price/mo
        - Region also effects price
        - Disk size and the duration 
        - Compute and Disks costs are separate. The compute costs are the running costs - even if the VM is shut off, you will still be charged for disks
        - Storage transactions also cost
        - Transfer of data on to different region can be costly
    - **Storage account**
        - Capacity
        - Write operations
        - Container and read operations
- Likewise there are other components which you can look into such as database, Kubernetes, Azure functios
- You can also look at cost-analysis by subscription
- You can select you `subsciption || cost analysis` which will give you break down according to service name, location, resource group
- Optimizing costs
    - It the resourse is not being used, then delete it
    - You can look at it by going to the resource homepage and under the `monitoring` tab you can review whether a particular resource is being used
    - If the CPU usage is less than 6% then it can tell you that you can possibly reduce the instance size 
    - This way you can determine what the sizing of the resource can be, the catch is that there is always some downtown with changing the size - so this should be tested in the staging environment rather than production
- **Azure advisor service** from the main dashboard 
    - It can provide recommendations based on cost
    - For example it can inform about a reserve instance to save on cost over a VM that is running for a long time, but not being utilized
- **Budgets**
    - You can go to your `subscription || budgets under cost management` You can define a monthly amount, if that is exceeded, you will get an email notification
- **Azure Reserve Pricing**
    - It is a huge saving opportunity - if you buy a 1-3 year commitment to reserve instance
    - This is bascally a discount that is offered with a commitment to use that reserve for a specific duration of period
    - You do have the ability to cancel a reservation

- **Reviewing subscriptions based on tags**
    - Tags can be used to mark certain departments within a company
    - You can then filter costs for a particular department based on tags
    - Select a particular `subscription || cost analysis under cost management > under top bars with filter`, select the tag for the department you are looking to analyze costs
    - Tags work better at the level of an individual reseource rather then at the level of a resource group

- **Application insights**
    - Allows integration of application insights service with Azure webapp service can let you track live stats about the website
    - This offers infomation about how the users interact with the application e-g page views
    - If you work on a project through visual studio, there is an option to work with `application insights telemetry`
    - You will be able to see th GET requests, response code and response time
    - Visual studio can send the telemetry application insights data to a resource on Azure
    - On **Azure portal**
        - Create a webap resource from general resources
        - While creating the application insights resource, under monitoring you can add **Application insights** resource
            - you can then search the `application insights resource from resources || live metrics`
            - Before you will see anything on the live metrics you will have to publish your project from visual studio into the webap
            - You can also review performace of the appliation by going to the `application insights resource || performance`. Likewise other usefule features include `failures` and `users`
            - You can also configure `smart alerts `that utilize machine learning 
                - You can go to the `application insights resource || smart detection > settings - you can find smart detection rules`
            - You can also use the `continues expert feature` for data analysis
                - You can go to the `application insights resource || continues resource > add` Where you can specify what type of data you want to send to your storage account
 - **Azure Sentinel Service**
    - This is an Azure Cybersecurity Instrument that can perform SEIM (Security Information Event Management) and SOAR (Security Orchestration Automatied Response)
    - It consists of `connectors` that connects the data to services. For example Azure sentinel service can be connected to the Azure analytics workspace via the connectors
    - Data connectors also allow you to connect to the external services
    - Cybersecurity cycle: Visibility, Analytics, hunting, Incidents, Automation
    - **Azure Security Center** allows you to look at the visibiity and analytics phase of the cybersecurity cycle
    - Azure sentinel allows you to look at all the phases of the cybersecurity cycle - It is a separate resource than Azure sentinel
    - Then there are builtin workbooks and queries
    - You cannot enable the log analytic workspace to Azure Sentinel if you have already linked it with Azure Security center
    - `Steps`
        - Create a log analytics workspace
            - Select resource, location, name (e-g `sentinelworkspace`)
        - Select Azure Sentinel from the main resources || data connectors
            - Among the connectors you can select `Azure Active Directory` Then open up that connector 
            - There you can check mark the type of logs that can be sent to Azure Sentinel from the Azure Active Directory - these can incude sign in logs, audit logs etc
            - Likewise there are multiple connectors that you can link to Azure Sentinel, such as you can add `Azure activity` This will send all of Azure activity logs from Azure subscription to Azure Sentinel
            - Another useful connector is `Security events` from windows VM machines. This will require installation of an agent onto the windows VM
                - If you want to add Security events then you will also have to add that particular VM to Sentinel workspace
                - `Sentinel workspace || virtual machines > Select the VM from list > click connect` The connect here will install an agent on the VM that will manage transfering event logs to the sentinel workspace
                - You can manually look at the security events on a windows Vm by RDP to the VM and then opening `event viewer` > windows log > security there you can see all the recorded security events
        - **Workbooks**
            - If you go to `Azure sentinel resource || data connectors`, Once you select a data connector then under the `next` tab you will see a set of recommended workbooks > view templates - you can visualize a lot of the data that way
            - The benifit of looking at these workbooks is that you do not have to look at the `event viewer` by manually going to a machine

# Azure Security and Identity

- Two main steps: Authentication - verifying your username and password, the next step is authorization for a resource - this occurs at the subscription level and is user specific. 
- Hierarchy -> Resources > Resource groups > Subscriptions > Management groups (group subscriptions together) > Tenant root group
- Note that the permissions get inherited as you move down the hierarchy

## Azure Active directory

- You can create users, groups, roles and administrators
- Azure AD connect lets you connect your on premises users with the Azure active directory
- You can look at all the features available with the Azure active directory onto the Azure active directory pricing webpage
- The premium version of active directory also offers
    - Self-service password reset
    - Conditional access policies
    - Identity governanace, access reviews and privilidged idendity
    - The pricing is per user per month
- **Trust relation b/w Azure active directory and subscription**
- The subscription must trust the user in the Azure active directory, before it will allow access to the resources
- Go to Azure subscriptions > change directory - by default it will select your default directory - however you can creat addtional directories and then you can tell the subscription to trust the new directory
- There are pre-built roles that you can assign. 
    - 4 high level roles: Contributor (Cannot allow permissions for additional roles), owner, reader, User access Administrator
- **Creating a new user in Azure Active Directory**
    - `Active directory || users > new user` Its basically like creating a new e-mail based on the website that is linked to your Azure account
        - While you create the user you give it a username and password
        - The first time log in will require the user to change the password
        - Then you can sign in with this new username from the same Azure portal
            - This user will not be able to see any of the resources
    - You can grant acces to a user to a particular VM
        - Go to the `VM resource || Access control > Add > Add role assignment > reader role > Under select search a user`
        - Once this access has been granted, if you log in with the same user account. You will now be able to see the VM on the dashboard
        - This user will only be able to have limied access to this VM as we previously only permitted `read` level access - for example the user will not be able to see the IP address and subnet associated with the VM - these are separate resources and the user did not have access to these
        - To overcome this you can grant access to the user at the resource group level in addition to the VM level to which the VM is part of
            - Once this is scuccessfull, then when you log in with this user you will now be able to see all the resources listed on the dashboard if you log on to the resource with this user
            - This user will not be able to stop the VM as this user was not granted with `contributor` level access
- **Azure Active Directory roles that can be assigned to the users**
- Note that the Subscription based roles (Role based access control - subscription level) is different from Azure Active directory roles
- Role based access control is more of an administrative level permission as to what level of permissions this user can further assign, where as Azure active directory roles are limited to the resource group access
        - **Dedicating some administrative roles to the users**
            - While logged in as the root admin Azure active directory || Roles and administrators
                - There you can see what role is currently assigned to the account - for the root admin its `global administrator`
                - Then you can select a particular user from the search and assign it a role
                - From the default root user account `Azure AD || Users > find the user > Assigned roles > Add assignment > Select role of User administrator` - This will allow the user to manage the users - including creating new users
                - You can also decide the assignment type elligible vs active (immediate)
- **Azure AD privilidged Identity management** - This feature is only available in Azure premium P2 license
    - The global administrator assigns special permissions to one of the user (prvilidged user) that can intern perform global administrator like functions such as creating or deleting VM ir SQL databases
    - The problem is that If this user moves onto a different department, this privilidged access will need to be removed
    - To avoid this problem, Azure AD privilileged identity management can be used - the benifit it offers is of temporary nature
        - **Features**:Just in time and time-bound and requiring activation of privilidged roles, implement multi-factor authentication to active role and setting notifications when a privilidged role is activated, conduct access reviews
        - this feature can only be implemented with `premium access` of AD
    - Select the `privilidged identity management from general resources` 
        - There are two pathways, one is the active pathway the other is the eligibility pathway
        - In the active pathway, the privilidges go in effect right away - when setting this up you have to options of 
            - `Privilidged identity management || AZure AD roles under manage - THis leads to the default directory homepage || settings > Search for the user administrator role > edit`
                - On this page you will see the tabs of Activation, Assignment and Notification
                    - **Activation** - you can select where multi-factor identification is to be applied
                    - You can select max activation duration - this is the number of hrs the user with this privilidge have to perform certain tasks once activated
                    - **Assignment** - Here you can specify whether you want it to be a permanent elligible assignement or a permanent active assignment OR you can specify an expiration time (e-g expire after 15 days). The elligible option offers an additional layer of security as it does not go into effect right away, the user who is rendered this elligibility will have to perform the activation from his/her account
                    - **Notification** - Who should be notified when the role has been assigned
            - `Azure AD || users > search the user > click the user || assigned roles` - here you will be able to see the assignment
            - **Adding a new assignment**
                - `Azure AD || users > search the user > click the user || assigned roles > Add assignment > select user administrator role`
                    - Select assignment type as eligible - It will have a start and end date - This date range is only when this particular user will be eligible to take up this role
                    - Next if you go inside this user's account by logging in you will see that this user will now be able to activate this elligibility
                        - Home page after logging in, Azure active directory || all users - wont be able to add users yet
                        - search `privilidged identity management || my roles > there you can see the eligibility to take up the user administrator role`
                    - The elligibility will be available only during the specified dates, during which the user can activate this additional privilidge and once the privilidge is activated there will only be a set number of hrs during which the user can perform the task. However, within the eligibility period. The user will be able to reactivate for this role multiple times
- **Azure Reviews**
- Review to access whether the latest user roles are appropriate for group memberships and role assignments
- Reviews can be conducted for:
    - Security group members
    - Users assigned to an application
    - Azure AD role
    - Azure resource role
- For reviews in the AD and resource roles, the reviews must be conducted with the privilidged identity management
- Premium tasks
    - Member and guest users who are assigned as reviewers
    - Member and guest users who perform a self-review
    - Group owners who perform an access review
    - Application owners who perform an acces review
- P2 license is not required for uses with Global Administrator or User Administrator roles
- Go to the `default directory, privilidged identity management || access reviews > new`
    - There you can decide the date range and the frequency of reviews
    - Then you can select the role for which you are performing a review e-g review of all the user accounts that have `user administrator` privilidges
    - you can also select `reviewers` these are the user accounts that can conduct reviews - If you are doign the review yourself then you can add your user account
    - It will display a list of users for each of the user, you can click audit to see the logs
    - Here you will have to opportuity to `approve or deny` which will continue or take away the privilidge, e-g in this case it is user Administrator
    - Then if you go back on to `default directoy || access review > you will see an access review - click it to modify it`. 
        - If you have dinied the user then you will first have to `stop` the access review and then click `apply`

- **Discover Resources**
- `Privilidged identy management || Azure resources`
    - It will show the subscriptions e-g Test environment
    - Going to the subscription homepage also gives you a summary of Identity management activities
    - Here you will see various roles for example a basic reader role - this will let you modify it
        - You will have to options of setting up activation, assignment and notification settings

- **Azure AD identity protection**
- It is to detect problems logins
- It will analyze the day to day logins of a particular user and then determine any risk to the user as well as the organization
    - For example the login is coming form an ip address that is not really known
    - It can categorize the risk as high medium or low
    - Then you can also trigger an action for example block access, but trigger a password change
    - Utilization of these features like user risk policy and sign in risk policy require Azure AD premium subscription

- **Identity governance**
    - Search for a`ccess review in general resources || access reviews > New access review`
        - Here you can select teams and `groups` and select `scope` like all users etc
        - Next in the `reviews` tab, then you can select reviewer, select the admin account and select the frequency with which to perform the review. Then likewise you can select the days and the start date - you can also specify frequency like weekly review, monthly review etc
        - Asign it a name and then click create
        - You will get an email notification when the reciew is complete - through which you can take actions like approve or deny an access
        - You can see information about a user like their last day of signin - there will be automatic recommendations and if you agree with them you can accept of deny the recommendations or approve or deny separately

- **Azure Security Center**
    - You can go to this resource 
    - Gives an overview of the security posture of the resources
    - It provides an overall security  score
    - It scans the resources and gives you recommendations
    - Some recommendations are free, but for some more advanced recommendations you will have to pay
         - `Security center || overview || pricing` and settings will enable standard tier
         - Navigating to this tier you can see whats available for free and whats available with costs e-g with standard tier
         - E-g regulatory compliance dashboard and reports will not be available for free
         - Continues assessment and security recommendations as well as Azure secure score are fee features
         - If you scroll down further, you will see a list of all of your resources and you can select whether to enable a recommendation - This is based on `Azure policies`
         - **Azure Defencer**
         - `Security ceter || Azure defender` is another layer of security - It can be turned on under pricing and enabled for specific resources
    - **Just in time VM access feature of Azure defender**
        - `Security Center || Azure defender > scrolling down you will be able to see just in time VM access`
            - You will be able to see the unprotected VMs
            - Click the `just in time > under the not configure tab`
                - Then select the VM and click `enable JIT` This will lead you to configure ports - you can delete the ports that you do not need them to be open. Then click `save`
                - Once you have implemented this, you can double check it by going to that particular VM resource and under networking you can see the rules
                - You can now see in the VM resource || networking that a new rule has been created with a new priority and a default setting of `deny`
                - If you want your computer IP to obtain access, you can then either go to the `VM resource || connect > request access`
                - Alternatively you can go to `Security center || Azure defender > Just in time VM > request access`
                    - Here you can then select `myip` or enter an ip range and click `open port`
                    - This will add another security rule permiting the specific ip address


- `Azure Identity protection` - Detect suspiscious signins - more user specific
- `Azure privilidged identity protection` - Azure AD roles and Azure resources - more about granting privilidged access to a user
- `Azure Securty center` - lets you configure just-in-time VM access

- **Multi-factor authentication**
    - You can enable multi-factor authentication per user
    - `Azure active directry || all users > from top left drop-down select Multi-factor authentication`
    - You will see a list of users and then you can select and then click `enable`
    - Then the user when he/she logs on will be prompted to fill in infomation regarding which option to use for authentication such as a phone or an app

- **Conditional access policies** requires Azure AD premium license
    - `Default directory from dashboard || security || conditional access > new policy`
        - you can select the users or usergroups to which the policy should be applied
        - Next you can select the apps to which you want to policy to be applied to - for the azure portal its `microsoft azure management`
        - Under `access control > grant` There you can select whether you want to require multi-factor authentication for this group
        - You also have the option of at least one or all of the controls to be satisfied
        - Then `enable policy > on`

- **Azure Resource Locks**
    - This feature is designed to prevent accidental modification and deletion of critial resources
    - Locks can be applied at the resource level, subscripion level or resource group level
        -`Cannot delete lock` - Can update but not delete
        - `Read only lock` - Can neither update nor delete
    - Go to the `resource || locks > add` there you can also see the options for resource group and subscription
        - For example if you apply this option to a virtual machine resource, you will have the lock-type property where you can specify the type of lock you are looking to apply. For example if you chose the read only lock, you will not be able to increase the size of a VM
        - Even the global admin cannot override the lock
        - If you apply the lock at a resource group level, then the lock is inherited by all the resources within the rerource group

- **Azure policies**
    - There are general policies for a coorporation to manage restriction on how the architects can deploy resources, e-g a general policy setting a limit on the size of VMs that can be deployed
    - The will prevent from creating new resources that surpass the policy restrictions, but for the resources that are already created it will only mark and list them for you to take action
    - Search for `policy` in the general resources - This will lead to a policy dashboard that displays policy assignments
        - From the `policy dashboard > under categories > uncheck all and select compute` This will display all the policies in this categories that are available from Azure to be applied to resources
            - There if you select `allowed VM size SKUs` and then click `assign` - here you will have the option to select a subscription or a resource group
            - You also have the option to add exclusions
            - Here you can select the VM sizes that are allowed
    - Once the plolicy has been applied to a subscription, you will then be able to see the resources listed that are not compliant with that policy

- **Azure Blueprints**
    - Consists of `Artifacts` : - ARM templates - To create infrastructure
                                - Azure policies - To govern creation of infrastructure
                                - Resource groups
                                - Role-based access control - Creating users, or automatically assigning roles to a given user
    - These are the default architecture settings of a company to govern the deployment of resources
    - These are usually helpful for organizations with multiple management groups with multiple subscriptions
    - You create a blue print and then assign it to a subscription or a management group. If it is saved to a management group
    - Steps: `Defining, publishing and assigning`
    - Only a user with `contributor` level access can save a blue print
    - You can protect a blue print by applying resource locks
    - There are some pre-existing samples in Azure that can be used when designing blue prints
    - Even if you are the `tenant-root group` - the Root level user of the Azure account, you still need role assignment before you can create blue prints
        - In other words you will have to assign `owner` role or `contributer` role to the root account - The point is that even if you are the King administerator, this assignment is not in place by default and will need to be configured before this account can be used to create blue prints
    - You can also **Unassign** a blue print by going to `Blueprints || Assigned blueprints > right clicking the blue print and selecting unassign`
        - Note that unassigning a blue print does not undo the resources created when this particular blue print was published
    - **Creating a blue print**
        - `Searh blueprint in general resources || blueprint definitions > create blueprint`
            - You can either start with a sample or you can click `start with black blueprint`
                - **Basic tab**
                - Give it a name, select **definition loaction** (choose subscription or management group - even if you have no specific management groups, you will have a default tenant group, not that you must have at least `contributor` level access to be able to assign a subscription otherwise you will get an error)
                    - You can assign contributor role by goiing to `tenant root group || Access control > assign owner role` Note that this step has to be implemented and is not always there by default - so be sure to check that before creating blue prints - you will have to wait for 5 min before the role gets assigned
                - **Artifacts tab**
                    - Click `add artifact` - then in the pop up you can select artifact type: `policy, role, resource group, resource manager`
                    - Choose resource group - the name given here is the name for the artifact, not the resource. The resource group name is created dynamically - this will extract the resource name as a parameter from an existing resource or resource group to which this blue print will be assigned
                    - You can also assign static values for example a blue print maybe assigned only to a particular location
                    - You also have the option of assigining tag names
                    - Likewise you can add another `artifact as a policy`, so that which this blue print is published, a particular policy is automatically assigned. For example a policy for automatic backup of VMs
                    - Likewise you can add another `artifact as resource manager` - Here you can add JSON code to configure infrastructre, such as creating a storage account
                    - Likewise you can add another `artifact as role assignment` - Here you can select a particular user and give it an automatic role assignment such as `owner` whenever this blueprint is applied
                    - Once congifuration is complete and the artifacts have been added to the blue print, click `save draft` After this step, the blue print will be created in an `unpublished` state - which means that it has yet to be assigned
                    - You can go to `Blurprints || blueprint definitions` there you will see the list of blue prints that are created

                - **Publising and assigining the blue print** - This step deploys the blue print to create resources
                        - Select a blue print and right click ` publish blueprint`  specify the version  and click `publish`
                        - After the blue print has been published in `blueprints || blueprint definitions` select the blue print from a list that you just `published > right click > select assign blueprint`
                            - Here you will slect a `subscription`
                            - Select lock assignment such as do not delete or readonly option for the resources created
                            - Managed identity select `system assigned` this gives Azure temporary `owner` role in order to deploy all artifacts
                            - You also have the option of creating your own user managed identity if you select `user assigned` instead
                            - Next you will add in information about the resource group name - that you are now dynamically providing while deploying this artifact, you will also se the static assignement such as the location that you specified while creating the blue print
                            - Likewise you can fill in all the options for the dynamic resources that are to be created as part of this blue print, like how many VMs should be created, how many storage accounts should be created etc
                            - Finally click `Assign`
                            - Note that with the assignment of the blue print to the subscription, it will run the blueprint and creat all architechture policies etc in that subscription
                            - Then you can verify successful deployment by going to all resources and select your subscription
                            - You can also see the new resource created by its name under all resources. If you go to this r`esource group || access control > role assignments` you can see the users and their level of role assignment e-g where its limited to this particular role or the management group
                            - Likewise you can go to `policies` you will see a new policy that has been setup

    - **Applying Resource locks to a blue print**
        - `Blueprints || blue print definitions` you will see the exisiting blueprints > right click and select `assign blueprint > choose perscription,blue print version, select **do not delete**`
        - This action will automatically apply the feature of `not being able to delete` to all the resources that are created as part of this blue print
            - Even if you go to an individual resourse such as a storage account and go under `locks` you will not see anyindividualized locks, if this resource was created as part of Azure blue print which contained a policy artifact of not being able to delete any resources created when this blue print was published, the storage account will inherit this trait, and you not be able to delete it - even if you are the owner
                - If you want to delete it you will have to got to `Blueprints || assigned blurprints`and then `unassign` it from the subscription

    - **Application Objects**
        - For example application wanting to access to a storage account
        - It is like giving an application its own automatic user to access the storage account. The application object is the user for the application
        - `Azure active directory or default directory || app registerations > application object`
            - On this homepage you obtain the client ID, object ID and Tenant ID - these are specify markers of access that can be implanted onto the app object to match before connecting to the app object
            - In addition you can also create a client secret that you can store vault
            - You can create a secret by going to the `app resource || certificates and secrets`. You can copy the value of the secret and paste it into the app
            - If the app is trying to access an existing storage account, you will have to paste the URl of the storage account into the app
            - You can further configure authentication by going to `app resource || authentication`

    - **Azure Key vault**
        - Storing enctyption keys, certificates and secrets
        - Key vailt is the security guard between the application and database that checks application IDs
        - You can create a key vault by searching key vault in the resources and clicking create
            - Select a resource group, give name, location, slet the days for retaininng vault after deletion
            - Slect vault access policy
        - To create a secret you go to `key vault resource || secrets > generate`
        - From the key vault you can get the vault URI which you will have to link with the app
        - The connection link between the app and the Azure key vault is the secret and the connection between the Azure and App is a policy inside the vault that recognizes the application
            -`key vaule resource || access policies > create a new policy`
    
    - **Manged identities**
        - This is an alternative to application object
        - Here you give an identity to an Azure resource (for example a VM) as if it were a user that can directly access the storage account
        - To the identity you grant role based access control
        - Here you do not have to embed any details like client id, tenant id or secret into the application
        - You have to first enable the managed identity on a particular azure resource like a VM for example
        - Pre-requsits: Create a VM resource and a storage account resource. Inside th storage account create a container and in the container upload a text file
            - Go to the `resource || identity > Turn status on > save` - This step registers the resource with Azure active directory
        - Next you can go to the `storage account resource || access control >add`
            - This will open up add role assignment window
                - choose the role, e-g `reader`
                - under select select the rsource whose 'manage identity' you have created, VM in this case for example. If you have already created a managed identity for the VM then that VM will show up here automatically
            - Likewise you can repeat the same steps and let VM gain access to the blob by selecting the `data reader role`
        
    - **Disk encyption for Azure VMs using Key vault**
        - When a VM is created there is already a default level of encryption on the disk called `SSE- server side encryption`
        - You can create another layer of encryption using Azure key vault (called `ADE- Azure disk encryption`) - the process involves creating a new encryption key in the vault and then applying it onto the disk in the VM. You can specify whether you are doing it for the operating disk
            - Go to `Vm resource || disks > additional settings`
                - You can select between OS disks or both
                - Slect the key vault from a list
                - Then create a new key
                - Then select the new key
                - **Note that the key vault and the VM resource must be in the same region**
    
    - **Microsoft active directory**
        - You assign all devices to a domain and then link that domain to active directory
            -Authenticate/authorize users
            -Enforce security policies
            -Validate user permissions
        - Azure active directory and microsoft active directory are two different things
        - Microsoft active directory is what is installed onto a local on premisis server
        - **Azure AD connect** is then used to link the microsoft active directory with Azure AD connect
        - Some applications (legacy applications) may only run with microsoft active directory and not azure active directory
        - This connection allows users to make use of local microsoft active directory features as well as use the applications on Azure using the same user credentials
        - **Azure active directory domain services**
            - Search for Azure Domain service and create this resource
            - It creates a V net and VMs inside the Vnet - Takes about 45 minutes to complete
            - This will create a domain. You create the VM and then install microsoft active directory on it and then connect it to the domain

## Designing Data storage

- Types of data stores:
    - Storage accounts: 
    - SQL database: Install Oracle Microsoft SQL server, MYSQL database
    - Azure SQL database - platform as service
    - Azure SQL database Elastic pool - resources are shared across multiple SQL databases
    - Azure SQL managed instance - SQL database gets deployed onto a virtual network - Most secure, the communication between the database and the app does not happen over the public internet
    - Managed instance with CosmosDB - comprises of SQL api, table api, cassandra api, mongo api and gremlin api
    - Azure Cache for Redis - In memory datastorage
- **Authorization options**
    - `Azure active directory` - most secure
        - This is available for blob service (storing objects)
        - `Storage account || container` to see if you have blob data in place
        - Create a user in Azure active directory `Azure active dirctory > all users`
        - Then go to `storage account || access control > add` to assign a role and select the user you just created
            - Example roles to choose from: reader, storage blob data reader
        - Once you create a user in Azure AD, you will be able to directly log into Azure from the storage explorer
    - `Access keys `- easiest, but less secure - These are unique to a storage account - downside: they grant access to the entire storage account not just a particular service. You can access the keys at `storage account || access keys` - You can manage the storage accounts using **Azure storage explorer**. The keys link the storage explorer on your computer to the storage account to Azure. You can regenerate the keys is you suspect that an unauthorized access has been obtained
    - Creating shared `access signatures` - authorizing service, time bound access
        - Go to `storage account || shared access signature`
            - You have the option of setting the start and end time validity of signature - For example you can create a shared access signature to an external audit company
            - You can also define the allowed IP ranges
            - This generates a connection string
            - When you are linking to the Azure storage explorer, you can select Shared access signature instead of the keys

- **Storage Account access tiers**
    - Hot (frequent, default), Cool (atleast 30d storage) and Archive(atleast 180 storage) - configured by implementing lifecycle rules
        - `storage account || lifecycle management > add rule`
        - Rehydration: Accessing archived data (Archive -> hot or cool) - process takes time
    - Size based pricing: First 50TB is expensive then then next 450 and over 500 TB
    - Storage costs: size + read/write operations. Reading costs are very high for reading data in archived form + early deletion fee
    - You can select these settings: `storage account || configuration`
    - You can also change the tier for a particular data object e-g `storage account resource > images container > change tier`

- **Storage encryption**
    - `Storage account resource || encryption`
        - default option `microsoft-managed keys` alternative `customer-managed keys`
        - This default encryption is applied to data when not in use, when the data is in use by the app then it is decrypted
    - For custom control first **Create a key vault** - must be in the same location
        - `key vault || keys > generate`
    - Then when you are at `storage account || enctyption > customer-managed, select from key vault, select a key from vault and key`
        - This allows you to select the key vault and from the keys in it

- **Setting up access policies**
    - This can be applied at the container level
    - `container || policies` you can specify policies like read
    - When you create an access signature for access through the storage explorer, you can tie this policy to the signature. The storage explorer is bound by the policies tied to the access signature when you register a storage account using its URI
    - If you go back and change the policy linked to the storage container, that way you can also remove access, for example if you remove read privilidges
    - ANother option is **imutable blob storage**
        - `container in storage account || access policy > add policy under immutable blob storage`
        - Here you can select from further 2 types : 1) Time based retention -No one can change anything in the container for specified number of days
                                                   - 2) Legal hold

- **Azure SQL deployment**
    - Deploying SQL server onto a VM - This is the `infrastructure as service` option, benifit is pay as you go subscription option
    - The second option is deploying SQL server as `platform as service` Here you do not really configure any VMs - this is automatically taken care of by Azure - Benifits, automated backup, patching etc
    - The third option is `Azure SQL Manged instance` - useful if you are migrating, native Vnet integration
    - **Costing**
        - Based on DTUs - database transaction units- Basic, standard, premium (2ms vs 5ms latency, 25 vs 4 input output operations)
        - cost saving options: 
            - Using hybrid benifit using existing licenses
            - serverless - Auto-pause when not in use, scaling based on demand
            - You can scale up to 100TB storage
    - **Deploying an SQL server on Azure VM**
        - Search SQL server in main resources
            - Under `publisher`, choose `Microsoft`
            - You can select `SQL server 2019 on Windows server 2019` ( the latest version) - This will automatically create the VM and install SQL server init
            - Select the standard version from the drop down
            - Configure for VM and Vnet as usual, it will assign a public IP address
            - **SQL server settings tab** - the server that will be installed
                - Connectivity - private (within Vnet), open port 1433.
                - Enable SQL authentication
                - Then you can configure storage for the SQL server and select whether you aready have an SQL server license
    - **SQL database auditing**
        - Tracking database logs and rights
        - You can eneble it at the server or database level
        - Required for regulatory compliance
        - `database rsource || auditing > auditing on` Here you also have the option of doing so at server level
        - You can direct the logs to a storage account
        - You can also view the logs - the command query for SQL, user, IP
            - `databse resource || auditing > view audit logs at the top`
        - The storage account must be in the same region as the SQL server
    
    - **SQL diagnostics**
        - `database resource || diagnostic settings > add diagnostic settings`
            - gives you option to archive data to a storage account, send data to log analytics, select data to be sent
            - You can also specify the retention period for data of logs -Note that this retention setting does not affect the logs in the workspace. For changing policies in the retention in workspace, you have to go to the database resource
        - For looking at usage and the estimated costs you can go to:
            - `database workspace resource || usage and estimated costs > data retention`
            - By default data retention is for 30 days - can be increased
        




